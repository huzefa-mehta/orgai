{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GraphNLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN8L2SJjEH0HChPoXzmlWy+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huzefa-mehta/orgai/blob/main/GraphNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0vMesVXvmTO",
        "outputId": "be92f7a3-38c1-4c61-8eb1-bdf445b6be83"
      },
      "source": [
        "import spacy\n",
        "import os\n",
        "import re\n",
        "import csv\n",
        "import sys, getopt\n",
        "import warnings\n",
        "!pip install nbconvert\n",
        "warnings.filterwarnings('ignore')\n",
        "from spacy.lang.en import English\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from spacy import displacy\n",
        "!python3 -m spacy download en_core_web_md\n",
        "import en_core_web_md\n",
        "nlp = en_core_web_md.load()\n",
        "#!python -m spacy download en_core_web_lg\n",
        "#import en_core_web_lg\n",
        "#nlp = spacy.load('en_core_web_lg')\n",
        "from enum import Enum\n",
        "G = nx.Graph()\n",
        "class Relation(Enum):\n",
        "  PARTOF = 1\n",
        "  REPORTSTO = 2\n",
        "  NOTREPORTTO = 3\n",
        "  NOTPARTOF = 4\n",
        "  CHANGEREPORTTO = 5\n",
        "  CHANGEPARTOF = 6\n",
        "  ADD = 7\n",
        "  REMOVE = 8\n",
        "  TITLE = 9\n",
        "  PARTOFHEADS = 10\n",
        "\n",
        "relationString = {}\n",
        "relationString[Relation.PARTOF] = \"partof\"\n",
        "relationString[Relation.REPORTSTO] = \"reportsto\"\n",
        "debug = False\n",
        "critical_list = ['DV', 'Graphics']\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (5.6.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert) (4.7.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert) (2.6.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert) (3.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.6.0)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (2.11.3)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.3)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (5.1.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (1.4.3)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (4.3.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.4.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert) (20.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert) (1.15.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert) (1.1.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->nbconvert) (4.4.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert) (2.4.7)\n",
            "Requirement already satisfied: en_core_web_md==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz#egg=en_core_web_md==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (53.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ndWg-dDrQi5",
        "outputId": "fbaf4c98-8bcd-4026-d960-cbd6699d70ce"
      },
      "source": [
        "%time\n",
        "\n",
        "def is_csv(infile):\n",
        "    try:\n",
        "        with open(infile, newline='') as csvfile:\n",
        "            start = csvfile.read(4096)\n",
        "\n",
        "            # isprintable does not allow newlines, printable does not allow umlauts...\n",
        "            if not all([c in string.printable or c.isprintable() for c in start]):\n",
        "                return False\n",
        "            dialect = csv.Sniffer().sniff(start)\n",
        "            return True\n",
        "    except csv.Error:\n",
        "        # Could not get a csv dialect -> probably not a csv.\n",
        "        return False\n",
        "        \n",
        "def getSentences(text):\n",
        "    nlp = English()\n",
        "    nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
        "    document = nlp(text)\n",
        "    #for sent_i, sent in enumerate(document.sents):\n",
        "    #  for token in sent:\n",
        "    #    print(sent_i, token.i, token.text)\n",
        "    return [sent.string.strip() for sent in document.sents]\n",
        "\n",
        "company_members = []\n",
        "member_id=0\n",
        "\n",
        "def is_critical(name):\n",
        "  if name in critical_list:\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "def delete_member(name):\n",
        "  global company_members\n",
        "  for member in company_members:\n",
        "      print(member)\n",
        "      if(member[\"fn\"] == str(name) or member[\"ln\"] == str(name) or member[\"nn\"] == str(name)):\n",
        "        print(name, member)\n",
        "        company_members.remove(member)\n",
        "        return\n",
        "  return\n",
        "\n",
        "def find_member(name):\n",
        "  global company_members\n",
        "  names = name.split()\n",
        "  for member in company_members:\n",
        "    if(member[\"fn\"] == str(names[0]) or member[\"ln\"] == str(names[0]) or member[\"nn\"] == str(names[0])):\n",
        "      return member\n",
        "  if len(names) > 1:\n",
        "    for member in company_members:\n",
        "      if(member[\"fn\"] == str(names[1]) or member[\"ln\"] == str(names[1]) or member[\"nn\"] == str(names[1])):\n",
        "        return member\n",
        "  return None\n",
        "\n",
        "def find_member_old(name):\n",
        "  global company_members\n",
        "  for member in company_members:\n",
        "    if(member[\"fn\"] == str(name) or member[\"ln\"] == str(name) or member[\"nn\"] == str(name)):\n",
        "      n = member[\"fn\"]+\" \"+member[\"ln\"]\n",
        "      n = n.strip()\n",
        "      return member[\"id\"], str(n.strip())\n",
        "  return -1, name\n",
        "\n",
        "\n",
        "\n",
        "def add_member(fn, ln=\"\",nn=\"\",org=\"\", title=\"\", reports=[], critical=False):\n",
        "  global member_id\n",
        "  global company_members\n",
        "  member = find_member(fn)\n",
        "  if(member == None):\n",
        "    person = {\n",
        "      \"id\": int(member_id),\n",
        "      \"fn\": str(fn),\n",
        "      \"ln\": str(ln),\n",
        "      \"nn\": str(nn),\n",
        "      \"org\": str(org),\n",
        "      \"title\": str(title),\n",
        "      \"reports\": list(reports),\n",
        "      \"critical\": critical\n",
        "    }\n",
        "    if debug:\n",
        "      print(person)\n",
        "    company_members.append(person)\n",
        "    member_id=member_id+1\n",
        "\n",
        "def print_members():\n",
        "  global company_members\n",
        "  for member in company_members:\n",
        "    print(member)  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "node_dist_to_color = {\n",
        "    1: \"tab:red\",\n",
        "    2: \"tab:orange\",\n",
        "}\n",
        "edge_colors=[]\n",
        "prons = ['he', 'she', 'him', 'his', 'her', 'they', 'them', 'their']\n",
        "titles = ['CEO', 'Head', 'Director', 'Architect']\n",
        "def printGraph():\n",
        "\n",
        "    pos = nx.spring_layout(G)\n",
        "    plt.figure()\n",
        "    node_opts = {\"node_size\": 500, \"node_color\": \"w\", \"edgecolors\": \"k\", \"linewidths\": 2.0}\n",
        "    nx.draw_networkx_nodes(G, pos, **node_opts)\n",
        "    nx.draw_networkx_labels(G, pos, font_size=14)\n",
        "    nx.draw_networkx_edges(G, pos, width=2.0, arrowsize=20, arrowstyle='fancy', edge_color=edge_colors)\n",
        "    #nx.draw(G, pos, edge_color='black', width=1, linewidths=1,\n",
        "    #        node_size=500, node_color='seagreen', alpha=0.9,\n",
        "    #        labels={node: node for node in G.nodes()})\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def nodeName(name):\n",
        "  member = find_member(name)\n",
        "  sname = name.strip()\n",
        "  if(member != None):\n",
        "      if(member[\"ln\"] != \"\"):\n",
        "        sname=member[\"fn\"]+\" \"+member[\"ln\"]\n",
        "      else:\n",
        "        sname=member[\"fn\"]\n",
        "      sname=sname.strip()\n",
        "      return(sname)\n",
        "  return(sname)\n",
        "\n",
        "def addNode(name):\n",
        "  member=find_member(name)\n",
        "  fname = name\n",
        "  if(member == None):\n",
        "    names = name.split()\n",
        "    if len(names) > 1:\n",
        "        add_member(names[0], names[1])\n",
        "    else:\n",
        "        add_member(names[0])\n",
        "    G.add_node(name)\n",
        "  else:\n",
        "    fname=member[\"fn\"]+\" \"+member[\"ln\"]\n",
        "    fname=fname.strip()\n",
        "  return(fname)\n",
        "  \n",
        "\n",
        "def removeRelation(s,d):\n",
        "  print(\"Removing \", s,d)\n",
        "  sname=nodeName(s)\n",
        "  dname=nodeName(d)\n",
        "  member = find_member(sname)\n",
        "  if member != None:\n",
        "    reports = member[\"reports\"]\n",
        "    if reports != []:\n",
        "      reports.remove(dname)\n",
        "  member = find_member(sname)\n",
        "  if member != None:\n",
        "    reports = member[\"reports\"]\n",
        "    if reports != []:\n",
        "      reports.remove(sname)\n",
        "\n",
        "  if(G.has_edge(s,d)):\n",
        "    G.remove_edge(s,d)\n",
        "\n",
        "\n",
        "def addRelation(s, d, r, critical):\n",
        "  print(\"Adding \", s,d,r,critical)\n",
        "  sname = s\n",
        "  dname = d\n",
        "  if(r == Relation.TITLE or r == Relation.PARTOFHEADS or r == Relation.PARTOF):\n",
        "    sname = addNode(s)\n",
        "    member = find_member(sname)\n",
        "    d=d.strip()\n",
        "    member[\"critical\"] = member[\"critical\"] or critical\n",
        "    if(r == Relation.PARTOF):\n",
        "      member[\"org\"] = d\n",
        "    elif(r == Relation.TITLE):\n",
        "      member[\"title\"] = d\n",
        "    else:\n",
        "      member[\"org\"] = d\n",
        "      member['title'] = \"Head\"\n",
        "    return\n",
        "\n",
        "  if(r == Relation.REPORTSTO):\n",
        "    sname = addNode(s)\n",
        "    dname = addNode(d)\n",
        "    member = find_member(dname)\n",
        "    reports = member[\"reports\"]\n",
        "    reports.append(sname)\n",
        "    member[\"reports\"] = reports\n",
        "    #G.add_edge(sname, dname)\n",
        "    return\n",
        "\n",
        "\n",
        "\n",
        "  if(r == Relation.REMOVE):\n",
        "    sname = nodeName(s)\n",
        "    delete_member(sname)\n",
        "    if(G.has_node(sname)):\n",
        "      G.remove_node(sname)\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "\n",
        "  if(r == Relation.REPORTSTO):\n",
        "    edge_colors.append(\"tab:red\")\n",
        "  elif(r == Relation.PARTOF):\n",
        "    edge_colors.append(\"tab:blue\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "prev_doc = None\n",
        "prev_antecedent = None\n",
        "\n",
        "def find_person(doc, t):\n",
        "  for ent in doc.ents:\n",
        "    if ent.label_ == 'PERSON' and re.search(t.text, ent.text): \n",
        "      return ent\n",
        "  return t\n",
        "\n",
        "def is_title(t):\n",
        "  tlower = t.text\n",
        "  tlower = tlower.lower()\n",
        "  for item in titles:\n",
        "    if tlower == item.lower():\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "def is_unknown(t):\n",
        "  if(t.similarity(nlp(\"unknown\")) > 0.6):\n",
        "    return(True)\n",
        "  if(t.similarity(nlp(\"rumor\")) > 0.6):\n",
        "    return(True)\n",
        "  if(t.pos_ == \"VERB\" and t.similarity(nlp(\"remains\")) > 0.6):\n",
        "    print(\"remains\",t)\n",
        "    return(True)\n",
        "  if(t.pos_ == \"VERB\" and t.similarity(nlp(\"continue\")) > 0.6):\n",
        "    print(\"continue\",t)\n",
        "    return(True)\n",
        "  return(False)\n",
        "\n",
        "def addTitleOrg(member):\n",
        "  if(member == None):\n",
        "    return(\"\")\n",
        "  memberName = member[\"fn\"]+\" \"+member[\"ln\"]\n",
        "  s = memberName.strip()\n",
        "  paren=False\n",
        "  if member[\"title\"] != \"\":\n",
        "    paren=True\n",
        "    s=s+\"(\"+member[\"title\"]\n",
        "    if member[\"org\"] != \"\":\n",
        "      if(paren==False):\n",
        "        s=s+\"(\"\n",
        "        paren = True\n",
        "      s=s+\" \"+member[\"org\"]\n",
        "\n",
        "    if member[\"critical\"]:\n",
        "      if(paren==False):\n",
        "        s=s+\"(\"\n",
        "        paren = True\n",
        "      s=s+\" *\"\n",
        "    if paren:\n",
        "      s=s+\")\"\n",
        "  s=s.strip()\n",
        "  return(s)\n",
        "\n",
        "def graph2csv(filename):\n",
        "  f = open(filename, \"w\")\n",
        "  global company_members\n",
        "  for member in company_members:\n",
        "    if(member[\"title\"] == \"CEO\"):\n",
        "      mname=member[\"fn\"]+\" \"+member[\"ln\"]\n",
        "      mname=mname.strip()\n",
        "      s=mname+\"(\"+member[\"title\"]+\"),\\n\"\n",
        "      f.write(s)\n",
        "  for member in company_members:\n",
        "    #mname=member[\"fn\"]+\" \"+member[\"ln\"]\n",
        "    #mname=mname.strip()\n",
        "    mname = addTitleOrg(member)\n",
        "    for reports in member[\"reports\"]:\n",
        "      reportmem = find_member(reports)\n",
        "      s = addTitleOrg(reportmem)\n",
        "      s=s+\",\"+mname+\"\\n\"\n",
        "      f.write(s)\n",
        "  f.close()\n",
        "    \n",
        "\n",
        "\n",
        "def find_antecedent(sent_prev):\n",
        "  for ent in sent_prev.ents:\n",
        "    if ent.label_ == 'PERSON':\n",
        "      return ent\n",
        "  return None\n",
        "\n",
        "def relationship(doc):\n",
        "  if(doc.similarity(nlp(\"reports\")) > 0.6):\n",
        "    return Relation.REPORTSTO\n",
        "  elif(doc.similarity(nlp(\"part of\")) > 0.6):\n",
        "    return Relation.PARTOF\n",
        "  elif(doc.similarity(nlp(\"responsible\")) > 0.6):\n",
        "    return Relation.PARTOFHEADS\n",
        "  elif(doc.similarity(nlp(\"departure\")) > 0.6):\n",
        "    return Relation.REMOVE\n",
        "  elif(doc.similarity(nlp(\"join\")) > 0.6):\n",
        "    return Relation.ADD\n",
        "  elif(doc.similarity(nlp(\"moved\")) > 0.6):\n",
        "    return Relation.CHANGEPARTOF\n",
        "  elif(doc.similarity(nlp(\"be\")) > 0.6):\n",
        "    return Relation.TITLE\n",
        "  elif(doc.similarity(nlp(\"charge\")) >0.6):\n",
        "    return Relation.PARTOFHEADS\n",
        "  elif(doc.similarity(nlp(\"heads\")) > 0.6):\n",
        "    return Relation.PARTOFHEADS\n",
        "  else:\n",
        "    return None\n",
        "\n",
        "def is_relevant(doc):\n",
        "  global prev_doc\n",
        "  global prev_antecedent\n",
        "  global debug\n",
        "  if debug:\n",
        "    #displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})\n",
        "    print(doc)\n",
        "  subject = False\n",
        "  object = False\n",
        "  verb = False\n",
        "  subjects = []\n",
        "  objects = []\n",
        "  fromobjects = []\n",
        "  toobjects = []\n",
        "  root_sub = None\n",
        "  root_obj = None\n",
        "  relation = None\n",
        "  fromchange=False\n",
        "  tochange=False\n",
        "  fromobject = False\n",
        "  toobject = False\n",
        "  critical = False\n",
        "\n",
        "  prv_tok_dep = \"\"    # dependency tag of previous token in the sentence\n",
        "  prv_tok_text = \"\"   # previous token in the sentence\n",
        "\n",
        "  prefix = \"\"\n",
        "  modifier = \"\"\n",
        "\n",
        "\n",
        "\n",
        "  for t in doc:\n",
        "    ent = None\n",
        "    if (is_critical(t.text)):\n",
        "      critical = True\n",
        "    if (is_unknown(t)):\n",
        "      return False\n",
        "    if relation == Relation.CHANGEPARTOF and t.pos_ == 'ADP' and t.similarity(nlp(\"from\")) > 0.6:\n",
        "      fromchange=True\n",
        "    if relation == Relation.CHANGEPARTOF and (t.pos_ == 'ADP' or t.pos_ == 'PART') and t.similarity(nlp(\"to\")) >0.6:\n",
        "      tochange=True\n",
        "\n",
        "    if t.dep_ == \"compound\":\n",
        "      prefix = t.text\n",
        "        # if the previous word was also a 'compound' then add the current word to it\n",
        "      if prv_tok_dep == \"compound\":\n",
        "        prefix = prv_tok_text + \" \"+ t.text\n",
        "      \n",
        "      # check: token is a modifier or not\n",
        "    if t.dep_.endswith(\"mod\") == True:\n",
        "      modifier = t.text\n",
        "      # if the previous word was also a 'compound' then add the current word to it\n",
        "      if prv_tok_dep == \"compound\":\n",
        "        modifier = prv_tok_text + \" \"+ t.text\n",
        "    if t.pos_ == 'PROPN' or t.pos_ == 'PRON' or t.pos_ == 'NOUN' or t.pos_ == 'VERB' or t.pos_ == 'ADJ':\n",
        "      ent = None\n",
        "\n",
        "\n",
        "      if t.dep_ == 'nsubj' or t.dep_ == 'nsubjpass':\n",
        "        if t.pos_ == 'PROPN':\n",
        "          ent = find_person(doc, t)\n",
        "          ent = t\n",
        "          root_sub = ent\n",
        "        elif t.pos_ == 'PRON':\n",
        "          if (t.tag_ == 'PRP' or t.tag_ == 'PRP$') and prev_doc != None and t.text.lower() in prons:\n",
        "            ent = find_antecedent(prev_doc)\n",
        "            if (ent != None):\n",
        "              prev_antecedent = ent\n",
        "            elif(prev_antecedent != None):\n",
        "              ent = prev_antecedent\n",
        "        if (ent != None):\n",
        "          subject = True\n",
        "          #root_sub = ent\n",
        "\n",
        "      if t.dep_ == 'conj' and t.pos_ == 'PROPN' and root_sub != None and root_sub.is_ancestor(t):\n",
        "        subject = True\n",
        "        ent = t\n",
        "\n",
        "\n",
        "      if subject == True and ent != None:\n",
        "        #subjects.append(ent.text)\n",
        "        str = modifier+\" \"+prefix+\" \"+ent.text\n",
        "        subjects.append(str)\n",
        "        modifier=\"\"\n",
        "        prefix=\"\"\n",
        "\n",
        "      \n",
        "      if t.dep_ == 'pobj' or t.dep_ == 'attr' or t.dep_ == 'xcomp':\n",
        "        if t.pos_ == 'PROPN' or t.pos_ == 'NOUN':\n",
        "          ent = find_person(doc, t)\n",
        "          ent = t\n",
        "\n",
        "\n",
        "          if is_title(t):\n",
        "            verb = True\n",
        "            relation = Relation.TITLE\n",
        "\n",
        "          if relationship(t) != None:\n",
        "            relation = relationship(t)\n",
        "\n",
        "            verb = True\n",
        "          else:\n",
        "            root_obj = ent\n",
        "        elif t.pos_ == 'PRON':\n",
        "          if (t.tag_ == 'PRP' or t.tag_ == 'PRP$') and prev_doc != None and t.text.lower() in prons:\n",
        "            ent = find_antecedent(prev_doc)\n",
        "            if (ent != None):\n",
        "              prev_antecedent = ent\n",
        "            elif(prev_antecedent != None):\n",
        "              ent = prev_antecedent\n",
        "        if tochange == True and ent != None:\n",
        "          toobject=True\n",
        "        elif fromchange == True  and ent != None:\n",
        "          fromobject=True\n",
        "        elif relationship(t) == None and ent != None:\n",
        "          object = True\n",
        "          #root_obj = ent\n",
        "\n",
        "      if t.dep_ == 'conj' and root_obj != None and root_obj.is_ancestor(t):\n",
        "        if tochange == True:\n",
        "          toobject = True\n",
        "        elif fromchange == True:\n",
        "          fromobject = True\n",
        "        else:\n",
        "          object = True\n",
        "        ent = t\n",
        "      \n",
        "      if (t.pos_ == 'NOUN' or t.pos_ == 'VERB' or \n",
        "          (t.pos_ == 'ADJ' and t.dep_ == 'acomp')) and relationship(t):\n",
        "        relation = relationship(t)\n",
        "        verb = True\n",
        "        if(relation == Relation.ADD or relation == Relation.REMOVE):\n",
        "          object = True\n",
        "    \n",
        "      if toobject == True and ent != None:\n",
        "        toobjects.append(ent.text)\n",
        "      elif fromobject == True and ent != None:\n",
        "        fromobjects.append(ent.text)\n",
        "      elif object == True and ent != None:\n",
        "        str = modifier+\" \"+prefix+\" \"+ent.text\n",
        "        objects.append(str)\n",
        "        modifier=\"\"\n",
        "        prefix=\"\"\n",
        "    else:\n",
        "      modifier = \"\"\n",
        "      prefix = \"\"\n",
        "      prv_tok_dep = \"\"    # dependency tag of previous token in the sentence\n",
        "      prv_tok_text = \"\"\n",
        "  \n",
        "  if subject and (object or (fromobject and toobject)) and verb:\n",
        "    if(relation == Relation.CHANGEPARTOF or relation == Relation.CHANGEREPORTTO):\n",
        "      for i in subjects:\n",
        "        for j in toobjects:\n",
        "          addRelation(i, j, relation, critical)\n",
        "      for i in subjects:\n",
        "        for j in fromobjects:\n",
        "          removeRelation(i, j)\n",
        "    elif(relation == Relation.ADD or relation == Relation.REMOVE):\n",
        "      for i in subjects:\n",
        "        addRelation(i, None, relation, critical)\n",
        "    elif(relation == Relation.PARTOF or relation == Relation.REPORTSTO):\n",
        "      for i in subjects:\n",
        "        for j in objects:\n",
        "          addRelation(i, j, relation, critical)\n",
        "    elif(relation == Relation.TITLE):\n",
        "      for i in subjects:\n",
        "        for j in objects:\n",
        "          addRelation(i, j, relation, critical)\n",
        "    elif(relation == Relation.PARTOFHEADS):\n",
        "      for i in subjects:\n",
        "        for j in objects:\n",
        "          addRelation(i, j, relation, critical)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  return subject and (object or (fromobject and toobject)) and verb\n",
        "\n",
        "def processTranscript(transcript,csvFile=\"\"):\n",
        "  global prev_doc\n",
        "  global prev_antecedent\n",
        "  global debug\n",
        "  prev_doc=None\n",
        "  prev_antecedent=None\n",
        "  sentences = getSentences(transcript)\n",
        "  for doc in nlp.pipe(sentences):\n",
        "    t=is_relevant(doc)\n",
        "    if debug:\n",
        "      print(t)\n",
        "      #printGraph()\n",
        "    prev_doc=doc\n",
        "  if(csvFile != \"\"):\n",
        "    graph2csv(csvFile)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def addInitialGraph():\n",
        "  global debug\n",
        "  debug=False\n",
        "  initialTranscript = \"RS, AL and AR report to BK. \\\n",
        "   BK reports to Raja Koduri. \\\n",
        "   Jim Keller, DH and RT report to Murthy. \\\n",
        "   Murthy reports to Bob Swan. \\\n",
        "   RS is responsibile for 'CoS'. \\\n",
        "   AR is in charge of Harwdware. \\\n",
        "   AL is in charge of Silicon. \\\n",
        "   Raja Koduri reports to Bob Swan. \\\n",
        "   Bob Swan is the CEO. \\\n",
        "   Raja Koduri is in charge of Graphics. \\\n",
        "   JN reports to KT. \\\n",
        "   Greg Bryant and Rob Crooke report to Bob Swan. \\\n",
        "   KT is in charge of Central Cad. \\\n",
        "   KT and AZ report to DH. \\\n",
        "   SS reports to Tom Lantzh. \\\n",
        "   Navin Shenoy reports to Bob Swan \\\n",
        "   Jim Keller is in charge of Soc Eng. \\\n",
        "   SM, MH and BP report to Jim Keller. \\\n",
        "   SM is in charge of Configurable IP. \\\n",
        "   Tom Lantzh reports to Murthy. \\\n",
        "   SB reports to AM. \\\n",
        "   AM reports to SM. \\\n",
        "   SB is the technical architect. \\\n",
        "   KC, RK and UK report to Navin Shenoy. \\\n",
        "   Navin heads Server Biz. \\\n",
        "   Amnon Shashua heads MobileEye. \\\n",
        "   Amnon Shashua reports to Bob Swan. \\\n",
        "   MD reports to EG. \\\n",
        "   EG, RR and RO report to RG. \\\n",
        "   US and RG report to RT. \\\n",
        "   JZ is in charge of Soft IP. \"\n",
        "  processTranscript(initialTranscript, \"initial.csv\")\n",
        "  #if debug:\n",
        "  print_members()\n",
        "\n",
        "def processGraph():\n",
        "  global debug\n",
        "  debug = True\n",
        "\n",
        "  transcript = \"Lots of changes. \"\\\n",
        "                \"Murthy is gone, following Jim’s departure. \"\\\n",
        "                \"Raja now reports directly to Bob. \"\\\n",
        "                \"He remains responsible for Graphics, Architecture and Software. \"\\\n",
        "                \"BK and team continue reporting to him. \"\\\n",
        "                \"Multiple teams now reporting to Bob directly instead of via Murthy. \"\\\n",
        "                \"Tom Lantzsch’s IOT team among them.\"\\\n",
        "                \"Sandra moved from Networking to become HR head.\"\\\n",
        "                \"Amnon remains on Bob’s team, continues heading Mobileye.\"\\\n",
        "                \"Navin and Greg continue to run respective Data Platforms and Client business groups.\"\\\n",
        "                \"Randhir’s position is elevated, still running GSM but under Bob.\"\\\n",
        "                \"Josh Walden has mostly replaced Murthy running significant part of engineering execution.\"\\\n",
        "                \"Need to connect with AL on BK’s team, discuss new graphics architecture.\" \\\n",
        "                \"SM, BP and MH all report to Josh now, following Jim’s departure, and reversal of org announcement with DH’s role. \"\\\n",
        "                \"Rumored that DH will leave Intel.\"\\\n",
        "                \"AM and SB reporting structure to SM remains the same. AM remains SM’s trusted lieutenant, and relies on SB for frontend expertise\"\\\n",
        "                \"Need to stay close to RS for IP opportunities on BP’s team.\"\\\n",
        "                \"New changes could be rough for SS on Tom’s IOT team. He might follow Murthy.\"\\\n",
        "                \"Expect AR on SS’s staff to gain power.\"\\\n",
        "                \"KT will report to Josh running infrastructure. JN is key verification lead in KT org.\"\\\n",
        "                \"AZ will move under SM, centralizing the IP dev org.\"\\\n",
        "                \"Spoke with US on Randhir’s staff. \"\\\n",
        "                \"He will discuss next MRM with EG. Agenda to be determined. \"\\\n",
        "                \"Need to connect NZ (Cadence) with RG prior to Randhir meeting, will align prep with EG. \"\\\n",
        "                \"Also connect AD (Cadence) with NM for roadmap prior to MRM.\"\\\n",
        "                \"LT (Cadence) met with Navin to discuss datacenter investments. \"\\\n",
        "                \"EDA follow up needed with RK and KV. UK is software only.\"\n",
        "\n",
        "  processTranscript(transcript, \"revised.csv\")\n",
        "  if debug:\n",
        "    print_members()\n",
        "\n",
        "def run():\n",
        "  os.environ[\"SPACY_WARNING_IGNORE\"] = \"W008\"\n",
        "  G = nx.Graph()\n",
        "  company_members = []\n",
        "  addInitialGraph()\n",
        "  processGraph()\n",
        "\n",
        "run()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 10.7 µs\n",
            "Adding    RS   BK Relation.REPORTSTO False\n",
            "Adding    AL   BK Relation.REPORTSTO False\n",
            "Adding    AR   BK Relation.REPORTSTO False\n",
            "Adding    BK  Raja Koduri Relation.REPORTSTO False\n",
            "Adding   Jim Keller   Murthy Relation.REPORTSTO False\n",
            "Adding    DH   Murthy Relation.REPORTSTO False\n",
            "Adding    RT   Murthy Relation.REPORTSTO False\n",
            "Adding    Murthy  Bob Swan Relation.REPORTSTO False\n",
            "Adding    RS   CoS Relation.PARTOFHEADS False\n",
            "Adding    AR   Harwdware Relation.PARTOFHEADS False\n",
            "Adding    AL   Silicon Relation.PARTOFHEADS False\n",
            "Adding   Raja Koduri  Bob Swan Relation.REPORTSTO False\n",
            "Adding   Bob Swan   CEO Relation.TITLE False\n",
            "Adding   Raja Koduri   Graphics Relation.PARTOFHEADS True\n",
            "Adding    JN   KT Relation.REPORTSTO False\n",
            "Adding   Greg Bryant  Bob Swan Relation.REPORTSTO False\n",
            "Adding   Rob Crooke  Bob Swan Relation.REPORTSTO False\n",
            "Adding    KT  Central Cad Relation.PARTOFHEADS False\n",
            "Adding    KT   DH Relation.REPORTSTO False\n",
            "Adding    AZ   DH Relation.REPORTSTO False\n",
            "Adding    SS  Tom Lantzh Relation.REPORTSTO False\n",
            "Adding   Navin Shenoy  Soc Eng Relation.PARTOFHEADS False\n",
            "Adding   Jim Keller  Soc Eng Relation.PARTOFHEADS False\n",
            "Adding    SM  Jim Keller Relation.REPORTSTO False\n",
            "Adding    MH  Jim Keller Relation.REPORTSTO False\n",
            "Adding    BP  Jim Keller Relation.REPORTSTO False\n",
            "Adding    SM  Configurable IP Relation.PARTOFHEADS False\n",
            "Adding   Tom Lantzh   Murthy Relation.REPORTSTO False\n",
            "Adding    SB   AM Relation.REPORTSTO False\n",
            "Adding    SB technical  architect Relation.TITLE False\n",
            "Adding    KC  Navin Shenoy Relation.REPORTSTO False\n",
            "Adding    RK  Navin Shenoy Relation.REPORTSTO False\n",
            "Adding    UK  Navin Shenoy Relation.REPORTSTO False\n",
            "Adding   Amnon Shashua  Bob Swan Relation.REPORTSTO False\n",
            "Adding    MD   EG Relation.REPORTSTO False\n",
            "Adding    JZ Soft  IP Relation.PARTOFHEADS False\n",
            "{'id': 0, 'fn': 'RS', 'ln': '', 'nn': '', 'org': 'CoS', 'title': 'Head', 'reports': [], 'critical': False}\n",
            "{'id': 1, 'fn': 'BK', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': ['  RS', '  AL', '  AR'], 'critical': False}\n",
            "{'id': 2, 'fn': 'AL', 'ln': '', 'nn': '', 'org': 'Silicon', 'title': 'Head', 'reports': [], 'critical': False}\n",
            "{'id': 3, 'fn': 'AR', 'ln': '', 'nn': '', 'org': 'Harwdware', 'title': 'Head', 'reports': [], 'critical': False}\n",
            "{'id': 4, 'fn': 'Raja', 'ln': 'Koduri', 'nn': '', 'org': 'Graphics', 'title': 'Head', 'reports': ['BK'], 'critical': True}\n",
            "{'id': 5, 'fn': 'Jim', 'ln': 'Keller', 'nn': '', 'org': 'Soc Eng', 'title': 'Head', 'reports': ['  SM', '  MH', '  BP'], 'critical': False}\n",
            "{'id': 6, 'fn': 'Murthy', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': [' Jim Keller', '  DH', '  RT', 'Tom Lantzh'], 'critical': False}\n",
            "{'id': 7, 'fn': 'DH', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': ['KT', '  AZ'], 'critical': False}\n",
            "{'id': 8, 'fn': 'RT', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 9, 'fn': 'Bob', 'ln': 'Swan', 'nn': '', 'org': '', 'title': 'CEO', 'reports': ['Murthy', 'Raja Koduri', ' Greg Bryant', ' Rob Crooke', ' Amnon Shashua'], 'critical': False}\n",
            "{'id': 10, 'fn': 'JN', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 11, 'fn': 'KT', 'ln': '', 'nn': '', 'org': 'Central Cad', 'title': 'Head', 'reports': ['  JN'], 'critical': False}\n",
            "{'id': 12, 'fn': 'Greg', 'ln': 'Bryant', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 13, 'fn': 'Rob', 'ln': 'Crooke', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 14, 'fn': 'AZ', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 15, 'fn': 'SS', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 16, 'fn': 'Tom', 'ln': 'Lantzh', 'nn': '', 'org': '', 'title': '', 'reports': ['  SS'], 'critical': False}\n",
            "{'id': 17, 'fn': 'Navin', 'ln': 'Shenoy', 'nn': '', 'org': 'Soc Eng', 'title': 'Head', 'reports': ['  KC', '  RK', '  UK'], 'critical': False}\n",
            "{'id': 18, 'fn': 'SM', 'ln': '', 'nn': '', 'org': 'Configurable IP', 'title': 'Head', 'reports': [], 'critical': False}\n",
            "{'id': 19, 'fn': 'MH', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 20, 'fn': 'BP', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 21, 'fn': 'SB', 'ln': '', 'nn': '', 'org': '', 'title': 'technical  architect', 'reports': [], 'critical': False}\n",
            "{'id': 22, 'fn': 'AM', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': ['  SB'], 'critical': False}\n",
            "{'id': 23, 'fn': 'KC', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 24, 'fn': 'RK', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 25, 'fn': 'UK', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 26, 'fn': 'Amnon', 'ln': 'Shashua', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 27, 'fn': 'MD', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 28, 'fn': 'EG', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': ['  MD'], 'critical': False}\n",
            "{'id': 29, 'fn': 'JZ', 'ln': '', 'nn': '', 'org': 'Soft  IP', 'title': 'Head', 'reports': [], 'critical': False}\n",
            "Lots of changes.\n",
            "False\n",
            "Murthy is gone, following Jim’s departure.\n",
            "Adding    Murthy None Relation.REMOVE False\n",
            "{'id': 0, 'fn': 'RS', 'ln': '', 'nn': '', 'org': 'CoS', 'title': 'Head', 'reports': [], 'critical': False}\n",
            "{'id': 1, 'fn': 'BK', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': ['  RS', '  AL', '  AR'], 'critical': False}\n",
            "{'id': 2, 'fn': 'AL', 'ln': '', 'nn': '', 'org': 'Silicon', 'title': 'Head', 'reports': [], 'critical': False}\n",
            "{'id': 3, 'fn': 'AR', 'ln': '', 'nn': '', 'org': 'Harwdware', 'title': 'Head', 'reports': [], 'critical': False}\n",
            "{'id': 4, 'fn': 'Raja', 'ln': 'Koduri', 'nn': '', 'org': 'Graphics', 'title': 'Head', 'reports': ['BK'], 'critical': True}\n",
            "{'id': 5, 'fn': 'Jim', 'ln': 'Keller', 'nn': '', 'org': 'Soc Eng', 'title': 'Head', 'reports': ['  SM', '  MH', '  BP'], 'critical': False}\n",
            "{'id': 6, 'fn': 'Murthy', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': [' Jim Keller', '  DH', '  RT', 'Tom Lantzh'], 'critical': False}\n",
            "Murthy {'id': 6, 'fn': 'Murthy', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': [' Jim Keller', '  DH', '  RT', 'Tom Lantzh'], 'critical': False}\n",
            "True\n",
            "Raja now reports directly to Bob.\n",
            "Adding    Raja   Bob Relation.REPORTSTO False\n",
            "True\n",
            "He remains responsible for Graphics, Architecture and Software.\n",
            "remains remains\n",
            "False\n",
            "BK and team continue reporting to him.\n",
            "continue continue\n",
            "False\n",
            "Multiple teams now reporting to Bob directly instead of via Murthy.\n",
            "False\n",
            "Tom Lantzsch’s IOT team among them.\n",
            "False\n",
            "Sandra moved from Networking to become HR head.\n",
            "True\n",
            "Amnon remains on Bob’s team, continues heading Mobileye.\n",
            "remains remains\n",
            "False\n",
            "Navin and Greg continue to run respective Data Platforms and Client business groups.\n",
            "continue continue\n",
            "False\n",
            "Randhir’s position is elevated, still running GSM but under Bob.\n",
            "False\n",
            "Josh Walden has mostly replaced Murthy running significant part of engineering execution.\n",
            "Adding   Josh Walden  engineering execution Relation.PARTOF False\n",
            "{'id': 30, 'fn': 'Josh', 'ln': 'Walden', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "True\n",
            "Need to connect with AL on BK’s team, discuss new graphics architecture.\n",
            "continue Need\n",
            "False\n",
            "SM, BP and MH all report to Josh now, following Jim’s departure, and reversal of org announcement with DH’s role.\n",
            "Adding    SM   Josh Relation.PARTOFHEADS False\n",
            "Adding    SM   departure Relation.PARTOFHEADS False\n",
            "Adding    SM  org announcement Relation.PARTOFHEADS False\n",
            "Adding    SM   role Relation.PARTOFHEADS False\n",
            "Adding    BP   Josh Relation.PARTOFHEADS False\n",
            "Adding    BP   departure Relation.PARTOFHEADS False\n",
            "Adding    BP  org announcement Relation.PARTOFHEADS False\n",
            "Adding    BP   role Relation.PARTOFHEADS False\n",
            "Adding    MH   Josh Relation.PARTOFHEADS False\n",
            "Adding    MH   departure Relation.PARTOFHEADS False\n",
            "Adding    MH  org announcement Relation.PARTOFHEADS False\n",
            "Adding    MH   role Relation.PARTOFHEADS False\n",
            "True\n",
            "Rumored that DH will leave Intel.\n",
            "False\n",
            "AM and SB reporting structure to SM remains the same.\n",
            "remains remains\n",
            "False\n",
            "AM remains SM’s trusted lieutenant, and relies on SB for frontend expertiseNeed to stay close to RS for IP opportunities on BP’s team.\n",
            "remains remains\n",
            "False\n",
            "New changes could be rough for SS on Tom’s IOT team.\n",
            "continue could\n",
            "False\n",
            "He might follow Murthy.\n",
            "continue might\n",
            "False\n",
            "Expect AR on SS’s staff to gain power.\n",
            "continue Expect\n",
            "False\n",
            "KT will report to Josh running infrastructure.\n",
            "continue will\n",
            "False\n",
            "JN is key verification lead in KT org.\n",
            "False\n",
            "AZ will move under SM, centralizing the IP dev org.\n",
            "continue will\n",
            "False\n",
            "Spoke with US on Randhir’s staff.\n",
            "False\n",
            "He will discuss next MRM with EG.\n",
            "continue will\n",
            "False\n",
            "Agenda to be determined.\n",
            "False\n",
            "Need to connect NZ (Cadence) with RG prior to Randhir meeting, will align prep with EG.\n",
            "continue Need\n",
            "False\n",
            "Also connect AD (Cadence) with NM for roadmap prior to MRM.LT (Cadence) met with Navin to discuss datacenter investments.\n",
            "False\n",
            "EDA follow up needed with RK and KV.\n",
            "continue follow\n",
            "False\n",
            "UK is software only.\n",
            "False\n",
            "{'id': 0, 'fn': 'RS', 'ln': '', 'nn': '', 'org': 'CoS', 'title': 'Head', 'reports': [], 'critical': False}\n",
            "{'id': 1, 'fn': 'BK', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': ['  RS', '  AL', '  AR'], 'critical': False}\n",
            "{'id': 2, 'fn': 'AL', 'ln': '', 'nn': '', 'org': 'Silicon', 'title': 'Head', 'reports': [], 'critical': False}\n",
            "{'id': 3, 'fn': 'AR', 'ln': '', 'nn': '', 'org': 'Harwdware', 'title': 'Head', 'reports': [], 'critical': False}\n",
            "{'id': 4, 'fn': 'Raja', 'ln': 'Koduri', 'nn': '', 'org': 'Graphics', 'title': 'Head', 'reports': ['BK'], 'critical': True}\n",
            "{'id': 5, 'fn': 'Jim', 'ln': 'Keller', 'nn': '', 'org': 'Soc Eng', 'title': 'Head', 'reports': ['  SM', '  MH', '  BP'], 'critical': False}\n",
            "{'id': 7, 'fn': 'DH', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': ['KT', '  AZ'], 'critical': False}\n",
            "{'id': 8, 'fn': 'RT', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 9, 'fn': 'Bob', 'ln': 'Swan', 'nn': '', 'org': '', 'title': 'CEO', 'reports': ['Murthy', 'Raja Koduri', ' Greg Bryant', ' Rob Crooke', ' Amnon Shashua', 'Raja Koduri'], 'critical': False}\n",
            "{'id': 10, 'fn': 'JN', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 11, 'fn': 'KT', 'ln': '', 'nn': '', 'org': 'Central Cad', 'title': 'Head', 'reports': ['  JN'], 'critical': False}\n",
            "{'id': 12, 'fn': 'Greg', 'ln': 'Bryant', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 13, 'fn': 'Rob', 'ln': 'Crooke', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 14, 'fn': 'AZ', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 15, 'fn': 'SS', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 16, 'fn': 'Tom', 'ln': 'Lantzh', 'nn': '', 'org': '', 'title': '', 'reports': ['  SS'], 'critical': False}\n",
            "{'id': 17, 'fn': 'Navin', 'ln': 'Shenoy', 'nn': '', 'org': 'Soc Eng', 'title': 'Head', 'reports': ['  KC', '  RK', '  UK'], 'critical': False}\n",
            "{'id': 18, 'fn': 'SM', 'ln': '', 'nn': '', 'org': 'role', 'title': 'Head', 'reports': [], 'critical': False}\n",
            "{'id': 19, 'fn': 'MH', 'ln': '', 'nn': '', 'org': 'role', 'title': 'Head', 'reports': [], 'critical': False}\n",
            "{'id': 20, 'fn': 'BP', 'ln': '', 'nn': '', 'org': 'role', 'title': 'Head', 'reports': [], 'critical': False}\n",
            "{'id': 21, 'fn': 'SB', 'ln': '', 'nn': '', 'org': '', 'title': 'technical  architect', 'reports': [], 'critical': False}\n",
            "{'id': 22, 'fn': 'AM', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': ['  SB'], 'critical': False}\n",
            "{'id': 23, 'fn': 'KC', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 24, 'fn': 'RK', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 25, 'fn': 'UK', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 26, 'fn': 'Amnon', 'ln': 'Shashua', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 27, 'fn': 'MD', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': [], 'critical': False}\n",
            "{'id': 28, 'fn': 'EG', 'ln': '', 'nn': '', 'org': '', 'title': '', 'reports': ['  MD'], 'critical': False}\n",
            "{'id': 29, 'fn': 'JZ', 'ln': '', 'nn': '', 'org': 'Soft  IP', 'title': 'Head', 'reports': [], 'critical': False}\n",
            "{'id': 30, 'fn': 'Josh', 'ln': 'Walden', 'nn': '', 'org': 'engineering execution', 'title': '', 'reports': [], 'critical': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "tc1pqtHurxd0",
        "outputId": "67f1ab31-c678-48bb-871d-5e44952b9184"
      },
      "source": [
        "\n",
        "\n",
        "def processFile(fname,csvFile):\n",
        "  fname = fname.strip()\n",
        "  if not is_csv(fname):\n",
        "    transcript=\"\"\n",
        "    with open(fname, 'r') as f:\n",
        "      transcript = f.read().replace('\\n', '')\n",
        "\n",
        "    f.close()\n",
        "    if(transcript):\n",
        "      processTranscript(transcript,csvFile)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "progname = \"orgai.py\"\n",
        "def main(argv):\n",
        "   global critical\n",
        "   critical_list = []\n",
        "   initial_transcript = ''\n",
        "   revised_transcript = ''\n",
        "   progname = \"orgai.py\"\n",
        "   argv = argv[1:]\n",
        "   try:\n",
        "      opts, args = getopt.getopt(argv,\"hi:r:c:\",[\"ifile=\",\"rfile=\",\"critical=\"])\n",
        "   except getopt.GetoptError:\n",
        "      print(progname, ' -i <initialtranscript> -r <revisedtranscript> -c <critical>')\n",
        "      return\n",
        "   for opt, arg in opts:\n",
        "      if opt == '-h':\n",
        "         print(progname, '-i <initialtranscript> -r <revisedtranscript> -c <critical>')\n",
        "         return\n",
        "      elif opt in (\"-i\", \"--ifile\"):\n",
        "         initial_transcript = arg\n",
        "      elif opt in (\"-r\", \"--rfile\"):\n",
        "         revised_transcript = arg\n",
        "      elif opt in (\"-c\", \"--critical\"):\n",
        "         critical_list = arg\n",
        "\n",
        "\n",
        "   print(critical_list)\n",
        "   if initial_transcript != '' and revised_transcript != '':\n",
        "        processFile(initial_transcript, \"initial.csv\")\n",
        "        processFile(revised_transcript, \"revised.csv\")\n",
        "   else:\n",
        "        print(progname, '-i <initialtranscript> -r <revisedtranscript>')\n",
        "\n",
        "\n",
        "   \n",
        "#orgai.py -i initial_transcript.txt -r revised_transcript.txt -c [\"graphics\", \"soc\", \"budget\", \"system\"]\n",
        "if __name__ == \"__main__\":\n",
        "  #main([\"orgai.py\",\"-i /content/initial_transcript\", \"-r /content/revised_transcript\", \"-c ['Graphics', 'SOC']\"])\n",
        "  main([\"orgai.py\",\"-i\", \"/content/initial_transcript\", \"-r\", \"/content/revised_transcript\", \"-c\", \"[SOC]\"])\n",
        "  #main(sys.argv)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[SOC]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0b6b46751c85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0;31m#main([\"orgai.py\",\"-i /content/initial_transcript\", \"-r /content/revised_transcript\", \"-c ['Graphics', 'SOC']\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"orgai.py\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"-i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/initial_transcript\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/revised_transcript\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-c\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"[SOC]\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m   \u001b[0;31m#main(sys.argv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-0b6b46751c85>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m     42\u001b[0m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritical_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0minitial_transcript\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrevised_transcript\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mprocessFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_transcript\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"initial.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mprocessFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrevised_transcript\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"revised.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-0b6b46751c85>\u001b[0m in \u001b[0;36mprocessFile\u001b[0;34m(fname, csvFile)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocessFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcsvFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtranscript\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-3977d2fa5920>\u001b[0m in \u001b[0;36mis_csv\u001b[0;34m(infile)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/initial_transcript'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzkenhgM1Mse",
        "outputId": "5e6a49bd-cb80-41e8-8263-b8c005d06195"
      },
      "source": [
        "\n",
        "#!jupyter nbconvert --to GraphNLP.py GraphNLP.ipynb\n",
        "#!pip install pyinstaller\n",
        "#!pyinstaller GraphNLP.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bin\t datalab  home\t lib64\topt   run   swift\t       tmp    var\n",
            "boot\t dev\t  lib\t media\tproc  sbin  sys\t\t       tools\n",
            "content  etc\t  lib32  mnt\troot  srv   tensorflow-1.15.2  usr\n",
            "[NbConvertApp] WARNING | pattern u'GraphNLP.ipynb' matched no files\n",
            "[NbConvertApp] ERROR | Error importing GraphNLP.py\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/nbconvert/exporters/base.py\", line 107, in get_exporter\n",
            "    return import_item(name)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/traitlets/utils/importstring.py\", line 34, in import_item\n",
            "    module = __import__(package, fromlist=[obj])\n",
            "ImportError: No module named GraphNLP\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/jupyter-nbconvert\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/jupyter_core/application.py\", line 267, in launch_instance\n",
            "    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/nbconvert/nbconvertapp.py\", line 338, in start\n",
            "    self.convert_notebooks()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/nbconvert/nbconvertapp.py\", line 497, in convert_notebooks\n",
            "    cls = get_exporter(self.export_format)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/nbconvert/exporters/base.py\", line 113, in get_exporter\n",
            "    % (name, ', '.join(get_export_names())))\n",
            "ValueError: Unknown exporter \"GraphNLP.py\", did you mean one of: asciidoc, custom, html, latex, markdown, notebook, pdf, python, rst, script, slides?\n",
            "Requirement already satisfied: pyinstaller in /usr/local/lib/python3.6/dist-packages (4.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pyinstaller) (3.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pyinstaller) (53.0.0)\n",
            "Requirement already satisfied: altgraph in /usr/local/lib/python3.6/dist-packages (from pyinstaller) (0.17)\n",
            "Requirement already satisfied: pyinstaller-hooks-contrib>=2020.6 in /usr/local/lib/python3.6/dist-packages (from pyinstaller) (2020.11)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->pyinstaller) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->pyinstaller) (3.4.0)\n",
            "44 INFO: PyInstaller: 4.2\n",
            "44 INFO: Python: 3.6.9\n",
            "44 INFO: Platform: Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "45 INFO: wrote /content/GraphNLP.spec\n",
            "47 INFO: UPX is not available.\n",
            "script '/content/GraphNLP.py' not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "id": "CoGvVjk5yhTf",
        "outputId": "93bee799-eba5-4213-ac97-4ea3a8d7bae7"
      },
      "source": [
        "!pip install gspread\n",
        "!pip install oauth2client\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pwd\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "\n",
        "scope = [\"https://spreadsheets.google.com/feeds\", 'https://www.googleapis.com/auth/spreadsheets',\n",
        "         \"https://www.googleapis.com/auth/drive.file\", \"https://www.googleapis.com/auth/drive\", \"/content\"]\n",
        "credentials = ServiceAccountCredentials.from_json_keyfile_name('/content/OrgAI-5ce11d05f14a.json', scope)\n",
        "print(credentials)\n",
        "client = gspread.authorize(credentials)\n",
        "\n",
        "spreadsheet = client.open('CSV-to-Google-Sheet')\n",
        "\n",
        "with open('data.csv', 'r') as file_obj:\n",
        "    content = file_obj.read()\n",
        "    client.import_csv(spreadsheet.id, data=content)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gspread in /usr/local/lib/python3.6/dist-packages (3.0.1)\n",
            "Requirement already satisfied: requests>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from gspread) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread) (2020.12.5)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.6/dist-packages (4.1.3)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client) (0.17.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client) (0.2.8)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client) (1.15.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client) (4.7)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-96477ca45cf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install oauth2client'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pwd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgspread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfs-auth-dance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m           \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}